// PDLL pattern spec to match an MLP and offload to an external function.

//
// ```
// void mlp_external(void *params, void *context, void *reserved)
// ```
//
// which is the expected signature of an external function implemented
// provided by a system plugin. See
// samples/custom_dispatch/cpu/plugin/system_plugin.c for an example.
//
// The `params` is the following struct
//
// ```
// struct mlp_params_t {
//   const float *restrict lhs;
//   size_t lhs_offset;
//   const float *restrict rhs;
//   size_t rhs_offset;
//   int32_t M;
//   int32_t N;
//   int32_t K;
//   float *restrict result;
//   size_t result_offset;
// };
// ```
//
// In MLIR this corresponds to the function
//
// ```
// func.func @mlp_external(%lhs : memref<..xf32>, %rhs : memref<..xf32>,
//     %M: i32, %N : i32, %K : i32, %result : memref<..xf32>)
// ```
//
// Note: In the above struct a `pointer, offset` pair represents a buffer
// passed into the external function. So any access to `lhs`, `rhs` and
// `result` is valid only if accessed as `lhs[lhs_offset + ...]`,
// `rhs[rhs_offset + ]` and `result[result_offset + ...]`.

// declare native rewrite called "rewriteAsFlowDispatch"
Rewrite rewriteAsFlowDispatch(
        op : Op, fn_name : Attr, 
        inputs : ValueRange, 
        repl_vals : ValueRange, 
        repl_dims : ValueRange, 
        other : ValueRange);


Constraint checkElementType(t1 : Type, t2 : Type);

Pattern mlp_tosa with benefit(1){
  let elemTy = type<"f32">;

  let matMulOp = op<tosa.matmul>(lhs : Value<LhsTy : Type>, rhs : Value<RhsTy : Type>) -> (MatMulTy : Type);
  checkElementType(LhsTy, elemTy);
  checkElementType(RhsTy, elemTy);
  checkElementType(MatMulTy, elemTy);

  let reluOp = op<tosa.clamp>(matMulOp.0) {
    min_int = attr<"0 : i64">,
    max_int = maxIntValue: Attr,
    min_fp = attr<"0.000000e+00 : f32">,
    max_fp = maxFloatValue: Attr
  } -> (ReluTy : Type);

  rewrite matMulOp with {
    let IntTy = type<"i32">;
    let IndexTy = type<"index">;
    let twoOp = op<arith.constant> { value = attr<"2 : index"> } -> (IndexTy);
    let oneOp = op<arith.constant> { value = attr<"1 : index"> } -> (IndexTy);
    let m = op<tensor.dim>(lhs, oneOp) -> (IndexTy);
    let n = op<tensor.dim>(rhs, twoOp)  -> (IndexTy);
    let k = op<tensor.dim>(lhs, twoOp); 
    let m_cast = op<arith.index_cast>(m)  -> (IntTy);
    let n_cast = op<arith.index_cast>(n) -> (IntTy);
    let k_cast = op<arith.index_cast>(k) -> (IntTy);



    let doRelu = op<arith.constant> { value = attr<"1 : i1">};
    let inputs = (lhs, rhs);
    let repl_vals = (reluOp.0 );
    let repl_dims = ();
    let other = (m_cast.0, n_cast.0, k_cast.0, doRelu.0);


    
    // The `rewriteAsFlowDispatch` is a rewrite function that allows
    // converting the matched dag into a call to the external function call
    // provided by a system plugin. The rewrite method expects the following
    // arguments
    // - the root of the matched DAG. This op will be erased after the call.
    // - `fn_name` the name of the function that is provided externally
    //   (using a plugin).
    // - `input_values` are values that are captures as the part of the match
    //   and are inputs to the match.
    // - `replaced_values` are the values that are captured as part of the
    //   match and are replaced by the `flow.dispatch`. The `flow.dispatch`
    //   returns as many values as `replaced_values` (and of same type).
    // - `replaced_values_dims` are the values for the dynamic dimensions of
    //   all the `tensor` values in `replaced_values`. For matches that could
    //   be static or dynamic, it should be assumed that the shape is dynamic
    //   and the value needs to be passed to the rewrite function.
    // - `other_operands` same as `input_values`, but kept separate to allow
    //   flexibility of where the results are passed through the ABI boundary.
    rewriteAsFlowDispatch(
      reluOp, attr<"\"mlp_external\"">, 
      inputs, repl_vals, 
      repl_dims, other);
  }; 
}
